<a name="readme-topo"></a>

<h1 align='center'>
  üßÆ Algoritmo de Classifica√ß√£o LAC
</h1>

<div align='center'>

[![SO][Ubuntu-badge]][Ubuntu-url]
[![IDE][vscode-badge]][vscode-url]
[![Make][make-badge]][make-url]
[![Linguagem][cpp-badge]][cpp-url]

Algoritmos e Estruturas de Dados I <br>
Engenharia de Computa√ß√£o <br>
Prof. Michel Pires da Silva <br>
CEFET-MG Campus V <br>
2024/1  
</div>

<details>
  <summary>
  <b style='font-size: 15px'>
    üìë Sum√°rio
  </b>
  </summary>
  <ol>
    <li><a href="#-Introdu√ß√£o">üîç Introdu√ß√£o</a></li>
    <li>
      <a href="#-Fundamenta√ß√£o-Te√≥rica">üí° Fundamenta√ß√£o Te√≥rica</a>
    </li>
    <li>
      <a href="#-Objetivos">üéØ Objetivos</a>
      <ul>
        <li><a href='#Objetivo-Geral'>Objetivo Geral</a></li>
        <li><a href='#Objetivos-Espec√≠ficos'>Objetivos Espec√≠ficos</a></li>
      </ul>
    </li>
    <li>
      <a href="#-Metodologia">üî¨ Metodologia</a>
      <ul>
        <li><a href='#Arquivos'>Arquivos</a></li>
        <li><a href='#Bibliotecas'>Bibliotecas</a></li>
        <li><a href='#Fun√ß√µes'>Fun√ß√µes</a></li>
        <li><a href='#Detalhes-de-Implementa√ß√£o'>Detalhes de Implementa√ß√£o</a></li>
      </ul>
    </li>
    <li>
      <a href="#-Testes-e-An√°lises-dos-Resultados">üìä Testes e An√°lises dos Resultados</a>
    </li>
    <li><a href="#-Conclus√£o">üèÅ Conclus√£o</a></li>
    <li>
      <a href="#-Come√ßando">üî® Come√ßando</a>
      <ul>
        <li><a href="#Pr√©-requisitos">Pr√©-requisitos</a></li>
        <li><a href="#Instalando">Instalando</a></li>
      </ul>
    </li>
    <li><a href="#-Ambiente-de-Compila√ß√£o-e-Execu√ß√£o">üß™ Ambiente de Compila√ß√£o e Execu√ß√£o</a></li>
    <li><a href="#-Refer√™ncias">üìö Refer√™ncias</a></li>
    <li><a href="#-Contato">üì® Contato</a></li>
  </ol>
</details>

<details> 
  <summary>
    <b style='font-size: 12px'> Abstract </b>
  </summary>
  Utilizando o algoritmo de classifica√ß√£o LAC, este projeto busca estrat√©gias para aprimorar seu desempenho quando aplicado √† classifica√ß√£o do conjunto de dados PokerHand Data-Set. Atrav√©s do uso de conceitos como sistema de caching de informa√ß√µes, otimiza√ß√µes de interse√ß√µes, predetermina√ß√£o de classifica√ß√µes, e tabelas hash LSH, estudamos melhores maneiras e adapta√ß√µes que permitem uma melhor gest√£o e um controle mais eficiente das classifica√ß√µes feitas pelo algoritmo. Dessa forma, ser√£o apresentados aqui os resultados provenientes de testes e estudos realizados para averiguar a efic√°cia da implementa√ß√£o dessas estrat√©gias em conjunto com o algoritmo em quest√£o, bem como outras abordagens adotadas com o objetivo de melhorar a performance em termos de tempo e acur√°cia ao realizar o procedimento. <br><br>
  üîë <b>Keywords:</b> Lac, Classifica√ß√£o, PokerHand Data-Set, Caching, Otimiza√ß√£o, Hash LSH
<br>
</details>

## üîç Introdu√ß√£o

<div align='justify'>

  Este [trabalho][trabalho-url] (Algoritmo de Classifica√ß√£o LAC) foi proposto na disciplina de Algoritmos e Estruturas de Dados I (AEDSI) pelo professor [Michel Pires da Silva][github-prof].

  A partir da base do algoritmo apresentado pelo Prof. Dr. Adriano Veloso em sua tese de doutorado [^1], neste projeto, iremos nos aprofundar em conceitos e pr√°ticas que visam melhorar a efic√°cia de tal algoritmo. O algoritmo apresentado em [^1], utiliza um conceito de treino e teste para classificar determinadas bases de dados. Primeiramente, o algoritmo busca mapear os dados a serem classificados por meio de ocorr√™ncias selecionadas, denominadas base de treino. Em seguida, ao ser apresentada a base de dados onde ser√° feita a classifica√ß√£o, chamada base de teste, o algoritmo, tendo acesso √†s informa√ß√µes coletadas no treino, pode utilizar conceitos como similaridade, confian√ßa e suporte para realizar a classifica√ß√£o de determinado conjunto de dados.

  Neste estudo, iremos aplicar tal algoritmo na classifica√ß√£o do conjunto de dados PokerHand Data-Set [^2]. Este conjunto de dados cont√©m todas as combina√ß√µes poss√≠veis para uma m√£o de cinco cartas no jogo de p√¥quer, bem como a categoria ou classe √† qual essa m√£o pertence. A disposi√ß√£o desse conjunto de dados √© feita da seguinte forma: formam-se 11 colunas para cada m√£o a ser analisada, onde cada coluna representa uma carta ou naipe, de forma que a √∫ltima coluna representa a classe √† qual essa m√£o pertence. Para cada m√£o, uma s√©rie com 11 colunas (10 cartas e 1 classe), as colunas √≠mpares, come√ßando por 1, representam os naipes, enquanto as colunas pares representam as cartas. Os dados s√£o codificados da seguinte forma:

  - ***NAIPES:*** 
    - **1**- Copas, **2**- Espadas, **3**- Ouros, **4**- Paus

  - ***CARTAS:***
    - **1**- √Ås, **2**- Dois, **3**- Tr√™s, **4**- Quatro, **5**- Cinco, **6**- Seis, **7**- Sete, **8**- Oito, **9**- Nove, **10**- Dez, **11**- Valete, **12**- Rainha, **13**- Rei

  - ***CLASSES:***
    - **0**- Nada em m√£os, **1**- Um par, **2**- Dois pares, **3**- Trinca, **4**- Sequ√™ncia, **5**- Flush, **6**- Full House, **7**- Quadra, **8**- Straight Flush, **9**- Royal Flush

  **Exemplo de representa√ß√£o (11D):**
  - **Dados:** 1, 11, 1, 13, 1, 10, 1, 12, 1, 1, 9
  - **Codifica√ß√£o:** Copas-√Ås, Copas-10, Copas-Valete, Copas-Dama, Copas-Rei, Royal Flush


  Dentre todas as classes presentes em nossa base de dados, algumas aparecem com mais frequ√™ncia do que outras. Por exemplo, a probabilidade de um jogador obter uma m√£o Royal Flush √© muito menor do que obter uma m√£o com apenas um par. Sendo assim, a frequ√™ncia de cada classe √© a seguinte. 
  - **0:** Nada em m√£os (49,95202%)  
  - **1:** Um par (42,37905%)
  - **2:** Dois pares (4,82207%)
  - **3:** Trinca (2,05118%)
  - **4:** Sequ√™ncia (0,37185%)
  - **5:** Flush: 54 ocorr√™ncias (0,21591%)
  - **6:** Full House: 36 ocorr√™ncias (0,14394%)
  - **7:** Quadra (0,02399%)
  - **8:** Straight Flush (0,01999%)
  - **9:** Royal Flush (0,01999%)

  Todas as combina√ß√µes de cartas e poss√≠veis m√£os no jogo de p√¥quer totalizam mais de um milh√£o de possibilidades. Para o treinamento de nosso algoritmo, foram selecionados 25 mil exemplos da base de dados original de forma a fornecer informa√ß√µes suficientes para que possamos classificar as demais amostras.

  Dessa forma, empregando a base do algoritmo LAC [^1] para realizar a classifica√ß√£o desta base de dados, iremos buscar meios de otimizar o procedimento de forma a aprimorar a acur√°cia obtida e o tempo gasto para classificar toda a base de dados.
</div>
<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>


## üí° Fundamenta√ß√£o Te√≥rica

<div align='justify'>

Neste estudo ser√£o utilizadas apenas as funcionalidades b√°sicas do algoritmo LAC, apesar de sua complexidade adicional devido a v√°rias implementa√ß√µes proposta pelo autor. O conceito base do algoritmo envolve o c√°lculo de vari√°veis como suporte e confian√ßa para determinar a qual classe uma determinada sequ√™ncia de dados pertence. Sendo assim, analisemos como se deu o procedimento base at√© a classifica√ß√£o final.

### üèãÔ∏è‚Äç‚ôÇÔ∏è Fase de Treino
Durante o processo de treinamento, nosso algoritmo mapeia todas as informa√ß√µes fornecidas da seguinte forma: a partir da posi√ß√£o (coluna) em que um dado est√° disposto, √© criado o conceito de tuplas, estruturas do tipo `<Chave, Valor>`, para mape√°-lo. Essas tuplas s√£o formadas a partir do valor da coluna em que o dado se encontra e do valor presente na mesma. Esse processo √© realizado para todas as cartas, deixando de fora as classes de cada linha.

- **Exemplo de tuplas geradas:**
  - **Dados:** [3, 3, 1, 1, 2, 3, 1]
  - **Mapeamento:** [(1, 3), (2, 3), (3, 1), (4, 1), (5, 2), (6, 3), 1]


Em conjunto com o mapeamento dos dados, s√£o criadas tabelas invertidas respons√°veis por armazenar as tuplas/features mapeadas e as linhas onde elas ocorrem. Dessa forma, s√£o criadas estruturas `<Chave, Valor>`, onde as chaves s√£o as tuplas/features e o valor √© um array de inteiros contendo todas as linhas onde essa feature ocorre.

<div align='center'>
  <img src='./images/tabelaFeatures.png' alt='Exemplo de Tabela Invertida de Features' width='300px'>
  <p>Exemplo de Tabela Invertida de Features</p>
</div>

 De maneira semelhante, √© criada uma tabela invertida respons√°vel por armazenar as classes e as linhas onde elas ocorrem, permitindo o controle sobre a qual classe cada linha do treinamento pertence.

<div align='center'>
  <img src='./images/tabelaClasses.png' alt='Exemplo de Tabela Invertida de Classes' width='300px'>
  <p>Exemplo de Tabela Invertida de Classes</p>
</div>

### üèÉ‚Äç‚ôÇÔ∏è Fase de Teste
Ap√≥s realizar o procedimento de treino e ter salvo em mem√≥ria todas as features presentes na base utilizada, bem como as linhas nas quais elas t√™m recorr√™ncias, e de forma semelhante para as classes, nosso algoritmo passa para a fase de teste. Nessa etapa, √© realizada finalmente a classifica√ß√£o de cada linha (m√£o de p√¥quer) presente na base de teste. 

Para realizar tal procedimento, nosso algoritmo executa as seguintes etapas: Primeiramente, realizamos o mapeamento dos dados de forma semelhante √† fase de treino, gerando tuplas/features, estruturas do tipo `<Chave, Valor>`. Semelhante √† fase de treino, essas features representam as colunas de cada valor e o valor presente em tal posi√ß√£o. 


<div align='center'>
  <img src='./images/mapeamentoTeste.png' alt='Exemplo de Mapeamento Fase de Teste' width='400px'>
  <p>Exemplo de Mapeamento Fase de Teste</p>
</div>

Realizado o mapeamento, acessamos na tabela invertida de features, criada na fase de treino, o array de inteiros que representa cada linha onde determinada feature aparece. Em seguida, realizamos um procedimento que realiza interse√ß√µes entre os arrays provenientes de cada tupla, ou seja, comparamos quais e quantas linhas determinadas tuplas t√™m em comum, de forma a fazer a an√°lise combinat√≥ria de todas as interse√ß√µes poss√≠veis. Durante esse procedimento, ao realizar as interse√ß√µes entre os arrays referentes a cada tupla, calculamos o suporte e a confian√ßa, vari√°veis respons√°veis por classificar cada m√£o. Ao calcular as interse√ß√µes para cada combina√ß√£o de features, iteramos sobre a matriz invertida de classes, criada durante o treinamento, e, para cada classe, fazemos a interse√ß√£o entre o array de inteiros que representa as linhas onde a classe aparece e o array resultante da interse√ß√£o da an√°lise combinat√≥ria das features. O nosso valor **confian√ßa** recebe o tamanho do vetor resultante dessa interse√ß√£o.

Por fim, na itera√ß√£o para cada classe, para calcular o suporte, dividimos o valor da **confian√ßa** pela quantidade de features presentes na base de dados constru√≠da durante o treinamento. Dessa forma, ao calcular o valor de suporte, este √© somado em um array `resultado`, que √© respons√°vel por guardar a soma do suporte para cada classe. Ap√≥s realizar todas as an√°lises combinat√≥rias poss√≠veis, a classe atribu√≠da para a m√£o ser√° aquela que tiver o maior valor de suporte no array `resultado`.

Conclu√≠mos, assim, o procedimento necess√°rio para realizar a classifica√ß√£o de cada m√£o/linha da base de dados [^2]. A seguir, veremos as otimiza√ß√µes propostas com o objetivo de aprimorar esse procedimento, buscando alcan√ßar resultados mais satisfat√≥rios em termos de tempo e acur√°cia, bem como a forma com a qual as mesma foram implementadas.

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üéØ Objetivos

<div align="justify">

  ### Objetivo Geral
  O objetivo geral deste estudo √© investigar e aprimorar a efic√°cia do algoritmo Lazy Associative Classifier (LAC) na classifica√ß√£o de uma grande massa de dados, utilizando o PokerHand Data-Set como um caso de estudo [^2]. Busca-se melhorar a precis√£o e efici√™ncia do processo de classifica√ß√£o, explorando otimiza√ß√µes para especificamente a fase de teste do algoritmo, buscando reduzir o tempo de execu√ß√£o e aumentar a acur√°cia das classifica√ß√µes realizadas.

  ### Objetivos Espec√≠ficos
  - Implementar o algoritmo LAC para classificar o PokerHand Data-Set, utilizando a metodologia baseada em suporte e confian√ßa para determinar as classes das m√£os de p√¥quer.
  - Analisar a precis√£o e o desempenho do algoritmo LAC com a implementa√ß√£o padr√£o no conjunto de dados, identificando poss√≠veis limita√ß√µes ou √°reas para melhoria. 
  - Desenvolver e testar t√©cnicas de otimiza√ß√£o que possam reduzir o tempo de execu√ß√£o do algoritmo sem comprometer a acur√°cia da classifica√ß√£o. 
  - Comparar os resultados obtidos ap√≥s a implementa√ß√£o das otimiza√ß√µes com os resultados da implementa√ß√£o padr√£o, avaliando melhorias em termos de efici√™ncia computacional e precis√£o da classifica√ß√£o. 
</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üî¨ Modelagem de Aplica√ß√£o 

<div aling='justify'>

  Partindo do conceito apresentado acima, √© poss√≠vel abordar diferentes solu√ß√µes para o nosso estudo. Nesta se√ß√£o, apresentaremos a forma com a qual modelamos o problema, bem como as estrat√©gias de otimiza√ß√£o empregadas para aumentar o desempenho em termos de acur√°cia das classifica√ß√µes e tempo gasto nessa tarefa. Para implementar nossa solu√ß√£o, a linguagem escolhida foi C++, uma vez que esta nos oferece um paradigma procedural que demonstra √≥timo desempenho ao lidar com o processamento de grandes volumes de instru√ß√µes e tamb√©m conta com a vantagem de ter diversas estruturas de dados implementadas que facilitam a modelagem da solu√ß√£o

  ### üìä Estrutura de Dados

  Compreendendo o procedimento proposto pelo algoritmo [^1], torna-se claro que, em alguns casos, estruturas de dados prim√°rias n√£o s√£o suficientes para construir uma solu√ß√£o ideal. Por exemplo, a constru√ß√£o das tabelas invertidas, tanto na fase de treino quanto na de teste. Sendo assim, torna-se mister o uso de estruturas de dados mais complexas, a fim de obter um c√≥digo limpo, que mantenha a consist√™ncia com o modelo apresentado e apresente bom desempenho.

  A come√ßar pelo exemplo citado acima, definamos como e com quais estruturas de dados foram implementadas as tabelas invertidas. Primeiramente, ao mapear as entradas de dados, antes mesmo de come√ßar a preencher as tabelas invertidas de features e classes, utilizou-se da estrutura `pair`, apresentada em [^3]. Essa estrutura nos permite armazenar dois valores em uma √∫nica vari√°vel, estabelecendo de forma clara o conceito de tupla, ideal para modelar esses dados. Fica evidente que os valores 
  armazenados em cada `pair` correspondem ao n√∫mero da coluna e ao valor presente na mesma, sendo, portanto, um `pair` 
  do tipo <int,int>. Essa estrutura foi utilizada ainda em outras partes da aplica√ß√£o, dada sua efic√°cia e facilidade de uso.

  Para a cria√ß√£o das tabelas invertidas, primeiramente referente √†s features, utilizou-se da estrutura `unordered_map`, apresentada em [^4]. Tal estrutura representa uma tabela que, novamente, utiliza-se do conceito <Chave, Valor>. Para modelar nossos dados, definiu-se que a chave para cada `unordered_map` seria uma estrutura do tipo `pair`, citada acima, e o valor contido na mesma seria representado por um `vector`, estrutura apresentada em [^5], uma esp√©cie de array dinamico, otimizado, de  f√°cil uso e com pouca necessidade de gerenciamento de mem√≥ria. Nessas tabelas, as estruturas do tipo `pair` representam as features, e as do tipo `vector` representam as linhas onde cada feature teve recorr√™ncia. De forma semelhante, deu-se a implementa√ß√£o da tabela invertida referente √†s classes, sendo que a √∫nica diverg√™ncia se deu ao fato de que as chaves utilizadas para preencher o `unordered_map` foram vari√°veis do tipo inteiro, que por sua vez representam as classes em quest√£o, enquanto seus valores, tamb√©m de forma semelhante, s√£o constitu√≠dos por um `vector` que armazena as linhas onde as mesmas apareceram na base de treino. Passemos, agora, para estruturas utilizadas durante o teste. 

  Como exemplificado no t√≥pico sobre o fundamento te√≥rico, durante o mapeamento de dados realizado na fase de teste, √© necess√°rio utilizar estruturas para modelar as features presentes nesta base de dados, de forma semelhante √†s usadas durante o processo de treino. Para tanto, utilizou-se a mesma estrutura `pair`. Continuando na mesma fase da aplica√ß√£o, utilizou-se novamente a estrutura do tipo `vector` para guardar os resultados das combina√ß√µes feitas entre as features de cada linha. Dessa vez, o valor armazenado foi um outro `vector`, criando-se o conceito de matriz, onde cada linha guardava a combina√ß√£o das features, estruturas do tipo `pair`, que posteriormente seriam utilizadas para fazer as interse√ß√µes e o c√°lculo do suporte e confian√ßa. Por fim, para armazenar os valores provenientes das interse√ß√µes feitas durante o processo de an√°lise combinat√≥ria, foi utilizada, novamente, a estrutura `vector`, uma vez que esta nos possibilita saber a quantidade de elementos armazenados nela de forma nativa, sem a necessidade de implementar nenhuma fun√ß√£o auxiliar.

  √â importante destacar a impossibilidade de utilizar determinadas estruturas de dados, como *chave*, em tabelas hash de forma nativa. Por exemplo, a necessidade de usar a estrutura `pair` como *chave* em uma estrutura `unordered_map` √© um caso espec√≠fico. Como a linguagem n√£o oferece suporte nativo para fun√ß√µes de hash para determinadas estruturas, foi necess√°rio criar fun√ß√µes de *hash* que lidam com essas estruturas, assim como fun√ß√µes de *equals* para validar a igualdade entre duas estruturas do mesmo tipo, a fim de utiliz√°-las como chave em outros contextos. Dessa forma, a limita√ß√£o de n√£o trabalhar de forma nativa pode impactar a performance do nosso algoritmo, embora o benef√≠cio da modelagem proposta supere os poss√≠veis malef√≠cios.

  ### üèãÔ∏è‚Äç‚ôÇÔ∏è Otimiza√ß√µes Propostas 

  Inicialmente, para termos no√ß√£o de quais partes de nosso algoritmo necessitam de mais otimiza√ß√£o, criamos a seguinte divis√£o de tarefas, onde cada parte representa um procedimento realizado. Nota-se que, para esta divis√£o, n√£o foram contabilizados os procedimentos realizados na fase de treino, uma vez que esta n√£o √© contabilizada no tempo de execu√ß√£o. Os procedimentos aqui apresentados dizem respeito apenas √† fun√ß√£o de teste:

  **1¬∫ Procedimento:** Leitura linha a linha do arquivo.

  **2¬∫ Procedimento:** Tokeniza√ß√£o/Mapeamento das informa√ß√µes contidas no arquivo para vari√°veis do tipo `vector`.

  **3¬∫ Procedimento:** An√°lise combinat√≥ria das tuplas/features, seguida da interse√ß√£o entre elas.

  **4¬∫ Procedimento:** C√°lculo de suporte e confian√ßa para a classifica√ß√£o.

  Para o 1¬∫ Procedimento, o custo √© linear, aumentando conforme a quantidade de linhas a serem lidas. Contudo, pode-se afirmar que, para a leitura de cada linha, este procedimento tem um custo constante, encontrando-se j√° em uma faixa de rendimento pr√≥ximo √† ideal. Dessa forma, embora existam poss√≠veis otimiza√ß√µes a serem feitas nesse sentido, elas n√£o impactar√£o de forma crucial a performance de nosso algoritmo.

  Analisando agora o 2¬∫ Procedimento, temos que, de forma semelhante ao 1¬∫ Procedimento, seu custo est√° pr√≥ximo da otimiza√ß√£o, uma vez que o custo para realiz√°-lo √© constante $\Theta(K)$, sendo **K** a quantidade de caracteres presentes em cada linha, que √© onze, no caso do PokerHand data-set. Conclui-se, ent√£o, que este procedimento tamb√©m n√£o surte efeito significativo para nossa aplica√ß√£o.

  Partindo para o 3¬∫ procedimento, onde se encontram as maiores oportunidades de implementar otimiza√ß√µes. Esse procedimento consiste em realizar a an√°lise combinat√≥ria entre todas as features e, durante esse processo, realizar a interse√ß√£o entre elas. O fato √© que existem diversas formas de implementar tanto a an√°lise combinat√≥ria quanto as interse√ß√µes entre os vetores. Contudo, tais procedimentos exigem um custo computacional significativamente maior em compara√ß√£o com todos os demais procedimentos realizados at√© ent√£o, independente da forma como forem implementados. A t√≠tulo de exemplifica√ß√£o, consideremos uma amostra da base de dados para ilustrar:

  **Dados:** 1, 11, 1, 10, 1, 12, 3, 8, 1, 9, 4

  Para este exemplo, temos um total de 1023 combina√ß√µes poss√≠veis, calculadas pela seguinte somat√≥ria:

$$
\sum_{k=1}^{10} C(10,k) = 1023
$$

  Isso significa que ser√° necess√°rio, na forma padr√£o da implementa√ß√£o proposta, realizar 1023 processos de interse√ß√£o entre vetores, sendo que, em alguns casos, se trata de interse√ß√µes entre nove ou mais vetores. Para cada interse√ß√£o entre dois ou mais vetores desordenados, que √© o caso de nossa aplica√ß√£o (uma vez que os vetores representam linhas que s√£o dispostas de maneira n√£o ordenada na tabela de features), o custo computacional √© dado por $\Theta(n_{1} \cdot n_{2} \cdot n_{3} \cdots n_{k})$, onde $n$ √© o tamanho de cada vetor. Com isso, vemos o quanto esse custo pode se tornar elevado √† medida que aumenta a quantidade de elementos a serem intersectados.

  #### Quando Realizar Interse√ß√µes:
  A partir deste ponto, surgem otimiza√ß√µes que podem ter um grande impacto na efici√™ncia do nosso algoritmo. Inicialmente, considerou-se a necessidade de n√£o realizar interse√ß√µes quando a an√°lise combinat√≥ria envolve apenas uma √∫nica feature, uma vez que sua interse√ß√£o ser√° ela mesma. Assim, ao realizar an√°lises combinat√≥rias de forma individual, basta acessar a tabela de features na chave correspondente e retornar as linhas que pertencem a essa feature. Embora essa melhoria pare√ßa insignificante, n√£o havia sido prevista inicialmente no modelo base apresentado na fundamenta√ß√£o te√≥rica, e ela evita processamentos desnecess√°rios. A partir dessa melhoria, define-se o conceito a ser seguido para as pr√≥ximas otimiza√ß√µes: evitar ao m√°ximo realizar interse√ß√µes desnecess√°rias e, se poss√≠vel, eliminar o processo de an√°lise combinat√≥ria.

  #### Cache de Interse√ß√µes
  Seguindo √† risca esse conceito, apresenta-se a primeira grande otimiza√ß√£o em rela√ß√£o ao modelo base apresentado anteriormente. Ao percebermos que, durante o processo de an√°lise combinat√≥ria e interse√ß√£o entre as *features* na fase de teste, muitas interse√ß√µes eram realizadas repetidamente, resultando em um grande tempo de processamento para repetir procedimentos j√° realizados, surgiu uma ideia para otimizar esse processo. Pensou-se, ent√£o, em seguir a ideia de mem√≥ria **cache**, presente na maioria dos computadores modernos, para utilizar uma tabela que armazenaria a classifica√ß√£o feita para an√°lises combinat√≥rias j√° realizadas. Dessa forma, ao encontrar um conjunto de *features* j√° processado anteriormente, nosso algoritmo realizar√° apenas uma busca na tabela de **cache**, economizando o processamento das interse√ß√µes e tamb√©m do c√°lculo de suporte e confian√ßa. Para maximizar a quantidade de informa√ß√µes poss√≠veis na mem√≥ria **cache**, ao realizar a an√°lise de um conjunto de *features* ainda n√£o processado, seu resultado/classifica√ß√£o ser√° salvo em uma tabela, tendo como chave um *array* de *pairs* que representam as *features* da an√°lise. Assim, na pr√≥xima vez que surgir a necessidade de processar o mesmo conjunto de *features*, ser√° feita uma busca na tabela; se tal conjunto j√° for uma chave armazenada, o processo de an√°lise ser√° ignorado, pois j√° se conhece o seu resultado. Para essa abordagem, quanto maior for a quantidade de dados a serem classificados, maior ser√° a utiliza√ß√£o da **mem√≥ria cache** e, consequentemente, maior o ganho de desempenho.

  #### Cache de Similaridade
  Atrav√©s da √∫ltima otimiza√ß√£o apresentada, os resultados de tempo de execu√ß√£o e acur√°cia tiveram um grande impacto positivo, possibilitando classificar massas de dados que antes n√£o eram poss√≠veis devido ao seu tamanho. Sendo assim, com o intuito de, ainda trabalhando com o conceito de mem√≥ria cache, obter performances ainda melhores, surgiu a pr√≥xima otimiza√ß√£o, que ser√° uma melhoria do conceito j√° apresentado. Inicialmente, o benef√≠cio que a mem√≥ria cache trazia para o fluxo de execu√ß√£o era a vantagem de n√£o precisar realizar determinadas interse√ß√µes, aproveitando as que j√° foram feitas e armazenadas em cache, evitando processamento desnecess√°rio e ganhando tempo. Contudo, a nova forma de implementar o sistema de cache se deu de maneira diferente, apresentando resultados ainda melhores de tempo e precis√£o durante as classifica√ß√µes.

  Na primeira vers√£o do cache, embora houvesse vantagens ao reutilizar interse√ß√µes j√° realizadas, ainda era necess√°rio realizar uma grande quantidade de interse√ß√µes, dado que o processo de an√°lise combinat√≥ria gera uma quantidade significativa de agrupamentos de features, tornando invi√°vel realizar todas. Assim, buscando reduzir ainda mais a necessidade de realizar interse√ß√µes desnecess√°rias, a nova abordagem visa classificar uma linha de forma completa baseada na sua similaridade com linhas j√° classificadas, sem precisar realizar nenhum processo de an√°lise combinat√≥ria e, portanto, nenhuma interse√ß√£o.

  Embora utilize conceitos diferentes para o reaproveitamento de processamento, a mem√≥ria cache utilizando similaridade de linhas opera de maneira semelhante √† primeira vers√£o, em seu conceito b√°sico. Seguindo o fluxo da aplica√ß√£o, inicialmente n√£o h√° como aproveitar nenhum processamento j√° realizado; por√©m, de maneira semelhante √† primeira vers√£o, quanto mais linhas o algoritmo classificar, maior ser√° o ganho produzido pelo sistema de cache. Uma vez realizada a classifica√ß√£o da primeira linha atrav√©s do conceito base de interse√ß√µes, o resultado da classifica√ß√£o √© armazenado em uma tabela hash; contudo, agora a chave da tabela ser√° um vector de pair, representando as features formadas pela linha classificada, e o valor armazenado ser√° a classe resultante da classifica√ß√£o realizada.

  A partir da segunda linha, antes mesmo de iniciar o procedimento de an√°lise combinat√≥ria, as features geradas atrav√©s do mapeamento passam por um processo de an√°lise de similaridade com as linhas j√° classificadas, que constituem as chaves da tabela de mem√≥ria cache com similaridade. Se houver uma linha j√° mapeada que apresente similaridade suficiente com a linha a ser mapeada, o valor de classifica√ß√£o atribu√≠do √† linha j√° classificada tamb√©m ser√° atribu√≠do √† linha a ser classificada, uma vez que a probabilidade de ambas pertencerem √† mesma classe √© muito grande. A partir dessa l√≥gica, a necessidade de se realizar o processo de an√°lise combinat√≥ria e interse√ß√µes diminui ainda mais, resultando em um grande ganho de desempenho. Conforme s√£o feitas as classifica√ß√µes, seus resultados s√£o armazenados na tabela, de forma que chega um determinado ponto da aplica√ß√£o em que n√£o √© mais necess√°rio processar nenhuma nova linha para classifica√ß√£o, uma vez que s√£o grandes as chances de se ter uma linha com coeficiente de similaridade semelhante ao apresentado.

  ##### Similaridade
  A partir do conceito apresentado, surge a necessidade de se definir qual m√©todo ser√° empregado para determinar a similaridade entre duas linhas, de forma a calcular se ambas s√£o suficientemente 'parecidas' para que compartilhem da mesma classe. Existem diversos meios de realizar tal processo, contudo, ainda que haja m√©todos com desempenho semelhante, a similaridade de cossenos foi a escolhida para essa tarefa. Uma vez que o procedimento para calcular a similaridade entre dois vetores espaciais √© realizado pelo m√©todo de similaridade de cossenos, atrav√©s de uma s√©rie de c√°lculos matem√°ticos, sua efic√°cia √© muito alta, assim como o tempo gasto para realizar tal processo. Este foi o principal aspecto considerado para a utiliza√ß√£o desse m√©todo, pois, uma vez que a similaridade entre duas linhas √© calculada diversas vezes durante a execu√ß√£o, outro m√©todo de c√°lculo de similaridade que exigisse mais processamento acabaria por prejudicar o desempenho do processo. Dessa forma, m√©todos como o c√°lculo de similaridade de Jaccard n√£o foram empregados, dado o tempo necess√°rio para realizar o c√°lculo de similaridade em cada opera√ß√£o. 

  ##### THRESHOLD
 O segundo conceito a ser analisado, para a correta implementa√ß√£o da otimiza√ß√£o apresentada acima, √© o limite necess√°rio de similaridade entre duas linhas, para que a classifica√ß√£o de uma possa ser feita com base na outra. Surge, assim, o conceito de threshold, uma rela√ß√£o m√≠nima de semelhan√ßa. Ao utilizar o m√©todo de similaridade de cossenos, observou-se que, embora apresente bons resultados, ainda h√° casos em que o c√°lculo de similaridade pode gerar ru√≠dos, ou seja, imprecis√µes aleat√≥rias durante o c√°lculo, como, por exemplo, aproximar n√∫meros como 7 e 8 de forma a gerar um valor alto de similaridade, mesmo que tal fato n√£o seja verdadeiro para a base de dados com a qual estamos lidando. Dessa forma, torna-se necess√°ria uma rela√ß√£o de similaridade alta, para que esses ru√≠dos n√£o interfiram no processo e gerem classifica√ß√µes imprecisas. Com isso, o valor escolhido como m√≠nimo de similaridade necess√°rio para se utilizar uma classifica√ß√£o j√° feita foi de 95\%, garantindo que a semelhan√ßa entre duas linhas seja suficientemente alta para que sejam agrupadas na mesma classifica√ß√£o.

  #### Irrelev√¢ncia para Classifica√ß√£o
  Para a pr√≥xima otimiza√ß√£o implementada, sua origem se deu ao analisar minuciosamente o procedimento de an√°lise combinat√≥ria. Verificou-se que, para determinado conjunto de *features*, ao realizar a interse√ß√£o entre as mesmas, a dimens√£o do *array* resultante era √≠nfima, de modo que, ao utilizar essa dimens√£o para, posteriormente, calcular a confian√ßa e o suporte para cada classe, obtinha-se um valor tamb√©m √≠nfimo para cada classifica√ßao. Em um cen√°rio ideal, onde o tempo n√£o impacta na performance, seria necess√°rio realizar todas as interse√ß√µes, ainda que seu resultado se aproximasse da irrelev√¢ncia para a classifica√ß√£o dos dados. Contudo, n√£o sendo este o cen√°rio proposto, optou-se por interromper o processo de an√°lise ao atingir um determinado est√°gio, onde as interse√ß√µes j√° n√£o tinham impacto consider√°vel nas classifica√ß√µes. Isso ocorre porque, quanto maior o conjunto de *features* analisadas, menor seria o *array* de interse√ß√£o e, consequentemente, menor o impacto nas classifica√ß√µes. Com a implementa√ß√£o dessa regra de gerenciamento, o n√∫mero de interse√ß√µes desnecess√°rias foi drasticamente reduzido, assim como o processamento necess√°rio para realiz√°-las. Observou-se tamb√©m que, conforme previsto, a acur√°cia das classifica√ß√µes n√£o sofreu preju√≠zo relevante, mantendo sua m√©dia anterior, com a √∫nica vantagem de melhorar o tempo gasto para realiz√°-las.

  #### Grid Search para Hiperpar√¢metros
  A partir do conceito implementado, de nao realizar o processo de analisse combinatoria a partir de um valor m√≠nimo para a dimens√£o do **array** de interse√ß√µes, surgiu a necessidade de um par√¢metro que definisse qual seria o limite ideal. A partir desse ponto, se deu a pr√≥xima implementa√ß√£o que traria resultados de otimiza√ß√£o para o LAC. Usando o conceito apresentado por L. He, Z. Gao, Q. Liu, e Z. Yang em [^6], o m√©todo **Grid Search** √© uma t√©cnica amplamente utilizada no contexto de aprendizado de m√°quinas, buscando ajustar hiperpar√¢metros para melhor desempenho de um modelo. A partir de uma s√©rie exaustiva de testes, o m√©todo retorna o melhor valor encontrado para ser usado em determinado par√¢metro. Dessa forma,  este m√©todo foi aplicado no contexto do LAC, mais especificamente em qual seria o valor m√≠nimo ideal para a dimens√£o do vetor de interse√ß√µes, para que seja relevante continuar realizando o processo de an√°lise combinatoria. Seguindo o conceito apresentado pelo GridSearch, o algoritmo foi executado diversas vezes com valores diferentes para o parametro em quest√£o. Como resultado da implementa√ß√£o desse m√©todo, chegamos a um par√¢metro que apresentou o melhor resultado entre todos os testes realizados, concluindo que a dimens√£o m√≠nima esperada para continuar a an√°lise seria de 10 unidades . Com isso, a implementa√ß√£o j√° feita, ponderando quando seria vi√°vel continuar com o processo de an√°lise combinat√≥ria, teve  um impacto ainda mais significativo, uma vez que obtivemos o par√¢metro melhor ajustado para quando parar esta etapa.
  
  

  #### Diminui√ß√£o de Cardinalidade
  Passemos para a pr√≥xima otimiza√ß√£o implementada durante este estudo. Tal implementa√ß√£o foi realizada visando seguir o conceito principal para a otimiza√ß√£o do algoritmo: fazer o m√≠nimo de interse√ß√µes poss√≠veis. Contudo, desta vez, a implementa√ß√£o ocorreu ao analisar os dados que eram submetidos para classifica√ß√£o, suas especificidades e como poder√≠amos us√°-los para melhorar a performance. Dessa forma, pensou-se que, se fosse poss√≠vel diminuir a quantidade de dados a serem processados, sem perder suas caracter√≠sticas, ou seja, sem desfigur√°-los, surtiria em um grande impacto, uma vez que seria necess√°rio realizar menos opera√ß√µes para classificar os mesmos dados. 

  Com isso, atrav√©s de um estudo espec√≠fico para a base PokerHand DataSet, viu-se que seria poss√≠vel diminuir a cardinalidade de cada linha/m√£o da seguinte forma: como cada par de colunas seguidas em nossa base de dados representa o naipe e o valor da carta, seria natural implementar um processo que possa juntar cada par de colunas, a fim de reduzir pela metade a quantidade de dados a serem classificados. Dessa forma, nossa base teria sua representa√ß√£o de 0 a 52, sendo cada valor a combina√ß√£o entre um naipe e um valor, formando, assim, uma carta. Diversas s√£o as formas de implementar processos que fa√ßam essa codifica√ß√£o, contudo, desde que n√£o atribuam valores repetidos para combina√ß√µes diferentes, a forma como ele lida com esse processo n√£o impacta significativamente em nosso algoritmo, embora quanto mais simples for a implementa√ß√£o, melhor ser√° o resultado obtido. A seguir, apresentamos a fun√ß√£o respons√°vel por fazer a codifica√ß√£o de cada par de valores.

**Algoritmo: Codifica√ß√£o de uma carta de baralho** 
```pseudo
Entrada: naipe, valor
Sa√≠da: carta

Fun√ß√£o codificacao(naipe, valor):
    carta ‚Üê (naipe - 1) * 13 + (valor - 1)
    Retorne carta
``` 
  A fim de economizar tempo e melhorar a performance, tal procedimento foi implementado durante o mapeamento das features, tanto na fase de treino quanto na fase de teste. Dessa forma, esta foi uma otimiza√ß√£o que tamb√©m impactou o 2¬∫ procedimento, n√£o se limitando apenas a ele. A t√≠tulo de exemplo, mostramos como se deu a transforma√ß√£o dos dados para uma determinada s√©rie de cartas:

  **Forma Padr√£o:** 1, 1, 1, 10, 1, 11, 1, 12, 1, 13, 9 

  **Transforma√ß√£o:** 
</div>
<div align='center'>
  (1, 1) ‚Üí 0 <br>
  (1, 10) ‚Üí 9 <br>
  (1, 11) ‚Üí 10 <br>
  (1, 12) ‚Üí 11 <br>
  (1, 13) ‚Üí 12 <br>
  (9) ‚Üí 9 <br>
</div>

<div align='justify'>
  Dessa forma, ao reduzir pela metade os dados a serem utilizados durante o processo de an√°lise combinat√≥ria, a efici√™ncia do nosso algoritmo teve um grande aumento, visto que ser√° necess√°rio realizar apenas 31 combina√ß√µes ao inv√©s de 1023, quantidade necess√°ria para a an√°lise de 10 valores. Essa redu√ß√£o, aplicada a todas as linhas do arquivo de teste, tem um grande impacto em todo o procedimento de classifica√ß√£o, sendo essa uma das principais otimiza√ß√µes implementadas.
 

 #### Multhreading
Uma vez que todos os procedimentos realizados para classifica√ß√£o, mesmo ap√≥s a implementa√ß√£o de todas as otimiza√ß√µes j√° citadas, n√£o s√£o dependentes entre si, podemos implementar multithreading em nosso algoritmo, visando a distribui√ß√£o de tarefas e execu√ß√£o em paralelo. Cada thread pode ser respons√°vel por uma parte espec√≠fica da an√°lise combinat√≥ria e, se necess√°rio, realizar a interse√ß√£o entre as features. No que diz respeito √† an√°lise combinat√≥ria e interse√ß√£o, cada thread pode processar uma parte da an√°lise, permitindo que as tarefas sejam realizadas simultaneamente. A interse√ß√£o dos resultados pode ser feita pelas threads conforme necess√°rio, garantindo que cada segmento da an√°lise seja tratado de forma eficiente.

√â crucial garantir que cada thread termine sua execu√ß√£o antes que o resultado final seja computado. Problemas de assincronia podem surgir se uma thread terminar sua execu√ß√£o antes de outras, o que pode levar a resultados incorretos ou inconsistentes. Portanto, a sincroniza√ß√£o entre threads √© essencial para evitar condi√ß√µes de corrida e inconsist√™ncias nos resultados, que devem ser gerenciadas cuidadosamente para garantir a integridade dos dados."Falar porque usar a biblioteca pthread em C++ e nao thread". "Falar porque usamos 5 threads, que foi o numero com melhor desempenho dados os testes executados"
 
Optamos por usar a biblioteca pthread em C++ em vez da biblioteca thread por v√°rias raz√µes. A pthread oferece maior controle sobre a cria√ß√£o e o gerenciamento de threads, al√©m de fornecer uma gama mais ampla de funcionalidades para sincroniza√ß√£o, como mutexes, sem√°foros e barreiras. Essas ferramentas s√£o essenciais em contextos onde a precis√£o e o controle detalhado das opera√ß√µes de multithreading s√£o cruciais. Al√©m disso, pthread √© uma biblioteca madura e amplamente utilizada, o que a torna uma escolha confi√°vel para aplica√ß√µes de alto desempenho.

Decidimos usar cinco threads, pois esse n√∫mero apresentou o melhor desempenho nos testes realizados. Ap√≥s experimentarmos com diferentes quantidades de threads, descobrimos que cinco era o n√∫mero ideal, equilibrando a carga de trabalho entre as threads e evitando a sobrecarga de gerenciamento que poderia ocorrer com um n√∫mero maior. Esse ajuste permitiu maximizar a efici√™ncia do processamento paralelo, mantendo o uso de recursos em um n√≠vel √≥timo.

A implementa√ß√£o de multithreading gerou √≥timos resultados, aumentando significativamente a efici√™ncia e a velocidade do algoritmo ao permitir a execu√ß√£o paralela de tarefas.

  Por fim, para o 4¬∫ Procedimento, a busca por m√©todos que pudessem otimiz√°-lo n√£o obteve tantos resultados quanto para o terceiro procedimento. Como apresentado na se√ß√£o de fundamento te√≥rico, o processo de c√°lculo de suporte e confian√ßa para a classifica√ß√£o de determinada linha/m√£o se d√° apenas realizando c√°lculos matem√°ticos, uma vez que a an√°lise combinat√≥ria e interse√ß√µes j√° foram realizadas. Sendo assim, ainda que a implementa√ß√£o do sistema de **mem√≥ria cache** surtisse impacto tamb√©m nesta fase da aplica√ß√£o, reduzindo a necessidade de realiz√°-lo, n√£o houve outra implementa√ß√£o que pudesse otimiz√°-lo, visto que o custo de realizar c√°lculos matem√°ticos tem pouco impacto durante a execu√ß√£o de nosso algoritmo, uma vez que tais instru√ß√µes possuem custo de execu√ß√£o constante.

  Em um contexto geral, buscando ainda outras formas de otimiza√ß√£o, ao ler a documenta√ß√£o da linguagem utilizada para desenvolver o LAC, viu-se que haviam determinadas estruturas de dados que possuem melhor performance do que as utilizadas na vers√£o inicial de nosso m√©todo. Entre tais estruturas de dados, figura-se principalmente o uso de `unordered set`, apresentado em [^7], no lugar do `vector`, estrutura usada para guardar os valores de recorr√™ncia de linhas tanto na fase de treino quanto durante o teste. Dessa forma, uma vez que o tempo de pesquisa fornecido pela estrutura `unordered set` se faz em tempo constante $\Theta(1)$, enquanto para o `vector` tem-se o custo linear $\Theta(n)$, em uma grande quantidade de pesquisas feitas, como no caso da nossa implementa√ß√£o do LAC, obt√©m-se um grande ganho de performance ao longo da execu√ß√£o at√© que seja realizada toda a classifica√ß√£o da base de dados em quest√£o. Com isso, finalizamos as implementa√ß√µes que buscaram otimizar o LAC enquanto classificava o PokerHand dataset. Podemos concluir que amplas foram as abordagens de otimiza√ß√£o, variando desde simplifica√ß√µes de processos at√© o estudo da base de dados para buscar melhores resultados, mostrando que diversos s√£o os meios de conseguir melhorar determinados processos e alcan√ßar ganhos em desempenho.

</div>


## üî¨ Metodologia

### Arquivos

<div align="justify">

  ### Bibliotecas

  ### Fun√ß√µes

  ### Detalhes de Implementa√ß√£o

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üìÇ Estrutura de Diret√≥rios

O projeto √© organizado da seguinte forma:

```.
|
‚îú‚îÄ‚îÄ datasets
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ poker-hand-testing.data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ poker-hand-training.data
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output.txt
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.cpp
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lac.cpp
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lac.hpp
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ make.sh
‚îú‚îÄ‚îÄ makefile
‚îî‚îÄ‚îÄ README.md
```

Esta estrutura de diret√≥rios facilita a organiza√ß√£o do projeto e a localiza√ß√£o dos arquivos necess√°rios para compilar o c√≥digo-fonte, executar o programa e visualizar os resultados.
<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üìä Testes e An√°lises dos Resultados

<div  align="justify">
  Analisar os resultados obtidos ap√≥s a implementa√ß√£o das otimiza√ß√µes propostas √© essencial para avaliar a efic√°cia das melhorias realizadas. Para isso, √© necess√°rio realizar testes com diferentes configura√ß√µes e comparar os resultados obtidos com a implementa√ß√£o padr√£o do algoritmo LAC. No decorrer da realiza√ß√£o deste estudo, foram realizados testes utilizando a implementa√ß√£o padr√£o do algoritmo e as otimiza√ß√µes propostas, a fim de avaliar a efic√°cia das melhorias implementadas. Os testes foram realizados em um ambiente controlado, com as mesmas configura√ß√µes de hardware e software, a fim de garantir a consist√™ncia dos resultados obtidos. A seguir, s√£o apresentados os resultados dos testes realizados, bem como as an√°lises feitas a partir dos mesmos.

  ### Configura√ß√µes dos Testes
  Primeiramente, teve-se a implementa√ß√£o padr√£o do algoritmo LAC, sem nenhuma otimiza√ß√£o, como base para os testes realizados. Em seguida, foram implementadas as otimiza√ß√µes propostas, uma a uma, a fim de avaliar o impacto de cada uma delas no desempenho do algoritmo. 

Posteriormente, decidimos fazer a implementa√ß√£o do cache de interse√ß√µes, com o objetivo de melhorar a efici√™ncia do algortimo ao parar de fazer interse√ß√µes repetidas. Ap√≥s os testes, pode-se afirmar que sua inser√ß√£o no projeto foi ben√©fica, pois reduz em grande quantidade o n√∫mero total de interse√ß√µes feitas. Uma curiosidade que foi observada e importante de ser destacada √© que esse cache de interse√ß√µes tem uma performance melhor na medida que a base a ser classificada √© maior, j√° que com isso o n√∫mero de interse√ß√µes repetidas a serem "retiradas" √© maior.

Depois disso e ainda n√£o conformados com o resultado obtido, resolvemos implementar a redu√ß√£o de cardinalidade. A redu√ß√£o de cardinalidade tem como objetivo diminuir a quantidade de caracter√≠sticas √∫nicas que o algoritmo precisa considerar, o que pode levar a economias significativas de mem√≥ria e a melhorias de desempenho. Como resultado, obtivemos:


<div align='center'>
  <img src='./images/reducaoCardinalidade.jpeg' alt='Resultados com redu√ß√£o de cardinalidade' width='600px'>
  <p>Resultados com redu√ß√£o de cardinalidade</p>
</div>

Ainda n√£o satisfeitos com o resultado, implementamos o cache de similaridade do cosseno. Essa m√©trica √© utilizada para medir a similaridade entre dois vetores, baseada no cosseno do √¢ngulo entre eles. Essa medida avalia a orienta√ß√£o dos vetores no espa√ßo multidimensional, ignorando seus comprimentos. O valor da similaridade do cosseno varia de -1 a 1, onde 1 indica que os vetores s√£o perfeitamente semelhantes, 0 indica que s√£o ortogonais (sem similaridade), e -1 indica que s√£o opostos.

No nosso trabalho, a similaridade do cosseno √© utilizada para comparar a similaridade entre caracter√≠sticas extra√≠das pelo algoritmo LAC. O objetivo √© melhorar a efici√™ncia do algoritmo ao armazenar e reutilizar resultados de similaridade atrav√©s de t√©cnicas de cache. Isso ajuda a reduzir o tempo de computa√ß√£o ao evitar recalcular a similaridade entre os mesmos pares de vetores repetidamente, especialmente em grandes volumes de dados.

Para a valida√ß√£o dessa implementa√ß√£o, foram feitos dois testes:

Teste 01 -> Com o Cache de Similaridade e sem Redu√ß√£o de Cardinalidade: Nesse teste, o resultado obtido se encontra na imagem abaixo:


<div align='center'>
  <img src='./images/cossenoSemReducao.jpeg' alt='Cache de Similaridade sem Redu√ß√£o de Cardinalidade' width='600px'>
  <p>Cache de Similaridade sem Redu√ß√£o de Cardinalidade</p>
</div>

Melhora de 20% na acur√°cia, com perda no tempo de execu√ß√£o.

Teste 02 -> Com o Cache de Similaridade e com Redu√ß√£o de Cardinalidade:  

Por fim, o √∫ltimo teste realizado foi utilizando ambos o cache de similaridade do cosseno e a redu√ß√£o de cardinalidade e, como resultado, temos:



<div align='center'>
  <img src='./images/cossenoComReducao.jpeg' alt='Cache de Similaridade com Redu√ß√£o de Cardinalidade' width='600px'>
  <p>Cache de Similaridade com Redu√ß√£o de Cardinalidade</p>
</div>

Obtendo, assim, melhora na acur√°cia e ganho de 98,11% no tempo de execu√ß√£o.


</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üèÅ Conclus√£o

O desenvolvimento e aprimoramento do algoritmo LAC, como apresentado neste trabalho, demonstram a efic√°cia e a flexibilidade dessa abordagem na resolu√ß√£o de problemas complexos de classifica√ß√£o. As melhorias implementadas, incluindo a utiliza√ß√£o de t√©cnicas de multithreading e otimiza√ß√µes espec√≠ficas, permitiram um ganho significativo de desempenho, tornando o algoritmo mais eficiente em termos de tempo de execu√ß√£o e utiliza√ß√£o de recursos.

Al√©m disso, a aplica√ß√£o de um cache de similaridade e a escolha criteriosa dos m√©todos de c√°lculo, como a similaridade de cossenos, refor√ßam a robustez do LAC em diferentes cen√°rios de classifica√ß√£o, especialmente em conjuntos de dados de alta dimensionalidade e com caracter√≠sticas complexas.

Os resultados obtidos confirmam que o LAC, aliado √†s otimiza√ß√µes propostas, √© uma ferramenta poderosa para a classifica√ß√£o de grandes volumes de dados, com potencial para ser aplicado em diversas √°reas, desde a minera√ß√£o de dados at√© o aprendizado de m√°quina. O uso de cinco threads, conforme determinado pelos testes, mostrou-se a escolha mais eficaz, equilibrando a carga de trabalho e maximizando a efici√™ncia do algoritmo.

Este trabalho abre portas para futuras pesquisas e melhorias adicionais, como a explora√ß√£o de novas t√©cnicas de otimiza√ß√£o e o estudo do impacto de diferentes estrat√©gias de paralelismo. A cont√≠nua evolu√ß√£o do LAC poder√° contribuir para sua aplica√ß√£o em contextos ainda mais desafiadores, mantendo sua relev√¢ncia no campo da ci√™ncia de dados.

<div  align="justify">

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üî® Come√ßando

Nesta se√ß√£o est√£o exemplificados os meios atrav√©s dos quais se tornam poss√≠veis a compila√ß√£o e execu√ß√£o do programa apresentado.

### Pr√©-requisitos

Inicialmente, algumas considera√ß√µes importantes sobre como se deve preparar o ambiente para compilar e executar o programa:

> [!NOTE]
> Recomenda-se usar uma distribui√ß√£o de sistema operacional Linux ou o Windows Subsystem for Linux (WSL), pois os comandos no [`makefile`][makefile] foram selecionados para funcionar em um ambiente [_shell/bash_][bash-url].

Considerando um ambiente _shell_, garanta que os seguintes comandos j√° foram executados:
  - Atualize os pacotes antes da instala√ß√£o dos compiladores:
  ```console
  sudo apt update
  ```
  - Instale a cole√ß√£o de compiladores ___GNU/g++___ e o ___make___:
  ```console
  sudo apt install build-essential
  ```
  - Se necess√°rio, instale o ___make___ individualmente:
  ```console
  sudo apt install make
  ```

### Instalando

Com o ambiente preparado, os seguintes passos s√£o para a instala√ß√£o, compila√ß√£o e execu√ß√£o do programa localmente:

1. Clone o reposit√≥rio no diret√≥rio desejado:
  ```console
  git clone https://github.com/alvarengazv/lac-algorithm.git
  cd lac-algorithm
  ```
2. Compile o programa com o ___make___, o que gera a pasta `build`, que cont√©m arquivos de objeto e um arquivo execut√°vel:
  ```console
  make
  ```
3. Execute o programa da pasta `build` ap√≥s a compila√ß√£o:
  ```console
  make run
  ```

4. Se necess√°rio, apague a √∫ltima compila√ß√£o da pasta `build`:
  ```console
  make clean
  ```

O programa estar√° pronto para ser testado.

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üß™ Ambiente de Compila√ß√£o e Execu√ß√£o

o trabalho foi desenvolvido e testado em v√°rias configura√ß√µes de hardware. Podemos destacar algumas configura√ß√µes de Sistema Operacional e Compilador, pois as demais configura√ß√µes n√£o influenciam diretamente no desempenho do programa.

<div align='center'>

![Ubuntu][ubuntu-badge]
![GCC][gcc-badge]
![Make][make-badge] 

SO | Compilador 
--- | ---
Ubuntu 24.04.4 LTS | g++ (Ubuntu 11.4.0-1ubuntu1~22.04)¬†11.4.0

</div>

> [!IMPORTANT] 
> Para que os testes tenham validade, considere as especifica√ß√µes
> do ambiente de compila√ß√£o e execu√ß√£o do programa.

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## ‚õè Makefile

O Makefile √© um utilit√°rio que automatiza o processo de compila√ß√£o e execu√ß√£o de programas. Aqui est√£o os principais comandos do Makefile para este projeto:

| Comando      | **Descri√ß√£o**                           |
|--------------|-----------------------------------------|
| `make`       | Compila o programa.                     |
| `make run`   | Executa o programa com o arquivo de entrada fornecido. |
| `make clean` | Remove os arquivos compilados.          |

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

## üì® Contato

<div align="center">
  <br><br>
     <i>Guilherme Alvarenga de Azevedo - Graduando - 3¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor1]
  [![Linkedin][linkedin-badge]][linkedin-autor1]
  [![Telegram][telegram-badge]][telegram-autor1]
  
  <br><br>
     <i>Jo√£o Paulo da Cunha Faria - Graduando - 3¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor2]
  [![Linkedin][linkedin-badge]][linkedin-autor2]
  
  <br><br>
     <i>Maria Eduarda Teixeira Souza - Graduando - 3¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor3]
  [![Linkedin][linkedin-badge]][linkedin-autor3]
  [![Telegram][telegram-badge]][telegram-autor3]
  
  <br><br>
     <i>Matheus Emanuel da Silva - Graduando - 3¬∫ Per√≠odo de Engenharia de Computa√ß√£o @ CEFET-MG</i>
  <br><br>
  
  [![Gmail][gmail-badge]][gmail-autor4]
  [![Linkedin][linkedin-badge]][linkedin-autor4]
  [![Telegram][telegram-badge]][telegram-autor4]

</div>

<p align="right">(<a href="#readme-topo">voltar ao topo</a>)</p>

üìö Refer√™ncias
-
[^1]: A. A. Veloso, "Classifica√ß√£o associativa sob demanda," Ph.D. disserta√ß√£o, Departamento de Ci√™ncia da Computa√ß√£o, Universidade Federal de Minas Gerais, Belo Horizonte, Brasil, 2009.

[^2]: R. Cattral and F. Oppacher, *Poker Hand*, UCI Machine Learning Repository, 2007. [Online]. Available: https://doi.org/10.24432/C5KW38.

[^3]: Microsoft, "pair structure," Microsoft Learn, 2024. [Online]. Available: https://learn.microsoft.com/pt-br/cpp/standard-library/pair-structure?view=msvc-170. [Accessed: Aug. 30, 2024].

[^4]: Microsoft, "unordered_map class," Microsoft Learn, [Online]. Available: https://learn.microsoft.com/pt-br/cpp/standard-library/unordered-map-class?view=msvc-170. [Accessed: Aug. 30, 2024].

[^5]: Microsoft, "vector class," Microsoft Learn, [Online]. Available: https://learn.microsoft.com/pt-br/cpp/standard-library/vector-class?view=msvc-170. [Accessed: Aug. 30, 2024].

[^6]: L. He, Z. Gao, Q. Liu, e Z. Yang, "An Improved Grid Search Algorithm for Parameters Optimization on SVM," Applied Mechanics and Materials, vol. 644-650, pp. 2216-2221, 2014. DOI: 10.4028/www.scientific.net/AMM.644-650.2216.

[^7]: "unordered_set Class | Microsoft Learn," Microsoft, [Online]. Available: https://learn.microsoft.com/pt-br/cpp/standard-library/unordered-set-class?view=msvc-170. [Accessed: 29-Aug-2024].


[vscode-badge]: https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white
[vscode-url]: https://code.visualstudio.com/docs/?dv=linux64_deb
[make-badge]: https://img.shields.io/badge/_-MAKEFILE-427819.svg?style=for-the-badge
[make-url]: https://www.gnu.org/software/make/manual/make.html
[cpp-badge]: https://img.shields.io/badge/c++-%2300599C.svg?style=for-the-badge&logo=c%2B%2B&logoColor=white
[cpp-url]: https://en.cppreference.com/w/cpp
[github-prof]: https://github.com/mpiress
[main-ref]: src/main.cpp
[branchAMM-url]: https://github.com/alvarengazv/trabalhosAEDS1/tree/AlgoritmosMinMax
[makefile]: ./makefile
[bash-url]: https://www.hostgator.com.br/blog/o-que-e-bash/
[lenovo-badge]: https://img.shields.io/badge/lenovo%20laptop-E2231A?style=for-the-badge&logo=lenovo&logoColor=white
[ubuntu-badge]: https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white
[Ubuntu-url]: https://ubuntu.com/
[ryzen5500-badge]: https://img.shields.io/badge/AMD%20Ryzen_5_5500U-ED1C24?style=for-the-badge&logo=amd&logoColor=white
[ryzen3500-badge]: https://img.shields.io/badge/AMD%20Ryzen_5_3500X-ED1C24?style=for-the-badge&logo=amd&logoColor=white
[windows-badge]: https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white
[gcc-badge]: https://img.shields.io/badge/GCC-5C6EB8?style=for-the-badge&logo=gnu&logoColor=white

[trabalho-url]:https://drive.google.com/file/d/11tvEmPrVSYZFsJzXbcc15Ags8CLRJByU/view?usp=sharing

[linkedin-autor1]: https://www.linkedin.com/in/guilherme-alvarenga-de-azevedo-959474201/
[telegram-autor1]: https://t.me/alvarengazv
[gmail-autor1]: mailto:gui.alvarengas234@gmail.com

[linkedin-autor2]: https://www.linkedin.com/in/jo%C3%A3o-paulo-cunha-faria-219584270/
[gmail-autor2]: mailto:joaopaulofaria98@gmail.com

[linkedin-autor3]: https://www.linkedin.com/in/maria-eduarda-teixeira-souza-2a2b3a254   
[telegram-autor3]: https://t.me/dudat_18
[gmail-autor3]: mailto:dudateixeirasouza@gmail.com

[linkedin-autor4]: https://www.linkedin.com/
[telegram-autor4]: https://t.me/
[gmail-autor4]: mailto:memanuel643@gmail.com

[linkedin-badge]: https://img.shields.io/badge/-LinkedIn-0077B5?style=for-the-badge&logo=Linkedin&logoColor=white
[telegram-badge]: https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&logo=telegram&logoColor=white
[gmail-badge]: https://img.shields.io/badge/-Gmail-D14836?style=for-the-badge&logo=Gmail&logoColor=white
